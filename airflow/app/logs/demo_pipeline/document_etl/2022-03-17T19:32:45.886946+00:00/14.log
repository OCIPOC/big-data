[2022-03-19 03:59:46,692] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: demo_pipeline.document_etl manual__2022-03-17T19:32:45.886946+00:00 [queued]>
[2022-03-19 03:59:46,704] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: demo_pipeline.document_etl manual__2022-03-17T19:32:45.886946+00:00 [queued]>
[2022-03-19 03:59:46,705] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-03-19 03:59:46,705] {taskinstance.py:1244} INFO - Starting attempt 14 of 14
[2022-03-19 03:59:46,705] {taskinstance.py:1245} INFO - 
--------------------------------------------------------------------------------
[2022-03-19 03:59:46,740] {taskinstance.py:1264} INFO - Executing <Task(SparkSubmitOperator): document_etl> on 2022-03-17 19:32:45.886946+00:00
[2022-03-19 03:59:46,742] {standard_task_runner.py:52} INFO - Started process 110 to run task
[2022-03-19 03:59:46,745] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'demo_pipeline', 'document_etl', 'manual__2022-03-17T19:32:45.886946+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/demo.py', '--cfg-path', '/tmp/tmpfeb8axhv', '--error-file', '/tmp/tmpv6kdvmp_']
[2022-03-19 03:59:46,746] {standard_task_runner.py:77} INFO - Job 32: Subtask document_etl
[2022-03-19 03:59:46,816] {logging_mixin.py:109} INFO - Running <TaskInstance: demo_pipeline.document_etl manual__2022-03-17T19:32:45.886946+00:00 [running]> on host 616fa5651a96
[2022-03-19 03:59:46,877] {taskinstance.py:1429} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=demo_pipeline
AIRFLOW_CTX_TASK_ID=document_etl
AIRFLOW_CTX_EXECUTION_DATE=2022-03-17T19:32:45.886946+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-03-17T19:32:45.886946+00:00
[2022-03-19 03:59:46,886] {base.py:70} INFO - Using connection to: id: spark_default. Host: spark://spark-master, Port: 7077, Schema: , Login: , Password: None, extra: {'queue': 'root.default'}
[2022-03-19 03:59:46,887] {spark_submit.py:335} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --name demo --queue root.default //usr/local/share_storages/spark_jobs/demo/job.py
[2022-03-19 03:59:48,030] {spark_submit.py:488} INFO - WARNING: An illegal reflective access operation has occurred
[2022-03-19 03:59:48,030] {spark_submit.py:488} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2022-03-19 03:59:48,031] {spark_submit.py:488} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2022-03-19 03:59:48,032] {spark_submit.py:488} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2022-03-19 03:59:48,032] {spark_submit.py:488} INFO - WARNING: All illegal access operations will be denied in a future release
[2022-03-19 03:59:48,371] {spark_submit.py:488} INFO - Job1 say hello!
[2022-03-19 03:59:48,977] {spark_submit.py:488} INFO - 2022-03-19 03:59:48.977198: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
[2022-03-19 03:59:48,978] {spark_submit.py:488} INFO - 2022-03-19 03:59:48.977248: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[2022-03-19 03:59:51,272] {spark_submit.py:488} INFO - Tensorflow: 2.8.0
[2022-03-19 03:59:51,355] {spark_submit.py:488} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2022-03-19 03:59:51,366] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SparkContext: Running Spark version 3.2.1
[2022-03-19 03:59:51,444] {spark_submit.py:488} INFO - 22/03/19 03:59:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2022-03-19 03:59:51,574] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO ResourceUtils: ==============================================================
[2022-03-19 03:59:51,577] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO ResourceUtils: No custom resources configured for spark.driver.
[2022-03-19 03:59:51,579] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO ResourceUtils: ==============================================================
[2022-03-19 03:59:51,582] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SparkContext: Submitted application: test
[2022-03-19 03:59:51,600] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2022-03-19 03:59:51,611] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
[2022-03-19 03:59:51,613] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2022-03-19 03:59:51,664] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SecurityManager: Changing view acls to: root
[2022-03-19 03:59:51,665] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SecurityManager: Changing modify acls to: root
[2022-03-19 03:59:51,666] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SecurityManager: Changing view acls groups to:
[2022-03-19 03:59:51,666] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SecurityManager: Changing modify acls groups to:
[2022-03-19 03:59:51,667] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
[2022-03-19 03:59:51,931] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO Utils: Successfully started service 'sparkDriver' on port 34131.
[2022-03-19 03:59:51,954] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SparkEnv: Registering MapOutputTracker
[2022-03-19 03:59:51,984] {spark_submit.py:488} INFO - 22/03/19 03:59:51 INFO SparkEnv: Registering BlockManagerMaster
[2022-03-19 03:59:52,001] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2022-03-19 03:59:52,002] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2022-03-19 03:59:52,007] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2022-03-19 03:59:52,033] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7a36b2d0-13aa-44c6-967c-5fd102f26d40
[2022-03-19 03:59:52,058] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2022-03-19 03:59:52,077] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO SparkEnv: Registering OutputCommitCoordinator
[2022-03-19 03:59:52,306] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2022-03-19 03:59:52,375] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://616fa5651a96:4040
[2022-03-19 03:59:52,557] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2022-03-19 03:59:52,652] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.2:7077 after 75 ms (0 ms spent in bootstraps)
[2022-03-19 03:59:52,854] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220319035952-0000
[2022-03-19 03:59:52,864] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32785.
[2022-03-19 03:59:52,865] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO NettyBlockTransferService: Server created on 616fa5651a96:32785
[2022-03-19 03:59:52,866] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2022-03-19 03:59:52,876] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 616fa5651a96, 32785, None)
[2022-03-19 03:59:52,883] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO BlockManagerMasterEndpoint: Registering block manager 616fa5651a96:32785 with 434.4 MiB RAM, BlockManagerId(driver, 616fa5651a96, 32785, None)
[2022-03-19 03:59:52,886] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 616fa5651a96, 32785, None)
[2022-03-19 03:59:52,889] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 616fa5651a96, 32785, None)
[2022-03-19 03:59:52,906] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220319035952-0000/0 on worker-20220319033803-172.18.0.4-7000 (172.18.0.4:7000) with 2 core(s)
[2022-03-19 03:59:52,910] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO StandaloneSchedulerBackend: Granted executor ID app-20220319035952-0000/0 on hostPort 172.18.0.4:7000 with 2 core(s), 2.0 GiB RAM
[2022-03-19 03:59:52,912] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220319035952-0000/1 on worker-20220319033803-172.18.0.3-7000 (172.18.0.3:7000) with 2 core(s)
[2022-03-19 03:59:52,914] {spark_submit.py:488} INFO - 22/03/19 03:59:52 INFO StandaloneSchedulerBackend: Granted executor ID app-20220319035952-0000/1 on hostPort 172.18.0.3:7000 with 2 core(s), 2.0 GiB RAM
[2022-03-19 03:59:53,146] {spark_submit.py:488} INFO - 22/03/19 03:59:53 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220319035952-0000/1 is now RUNNING
[2022-03-19 03:59:53,149] {spark_submit.py:488} INFO - 22/03/19 03:59:53 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220319035952-0000/0 is now RUNNING
[2022-03-19 03:59:53,206] {spark_submit.py:488} INFO - 22/03/19 03:59:53 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2022-03-19 03:59:53,565] {spark_submit.py:488} INFO - 22/03/19 03:59:53 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2022-03-19 03:59:53,598] {spark_submit.py:488} INFO - 22/03/19 03:59:53 INFO SharedState: Warehouse path is 'file:/airflow/spark-warehouse'.
[2022-03-19 03:59:54,347] {spark_submit.py:488} INFO - <SparkContext master=spark://spark-master:7077 appName=test>
[2022-03-19 03:59:54,373] {spark_submit.py:488} INFO - 2022-03-19 03:59:54.373138: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
[2022-03-19 03:59:54,374] {spark_submit.py:488} INFO - 2022-03-19 03:59:54.373223: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
[2022-03-19 03:59:54,375] {spark_submit.py:488} INFO - 2022-03-19 03:59:54.373864: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (616fa5651a96): /proc/driver/nvidia/version does not exist
[2022-03-19 03:59:54,376] {spark_submit.py:488} INFO - 2022-03-19 03:59:54.374487: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
[2022-03-19 03:59:54,378] {spark_submit.py:488} INFO - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2022-03-19 03:59:56,000] {spark_submit.py:488} INFO - Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5
[2022-03-19 03:59:56,149] {spark_submit.py:488} INFO - 22/03/19 03:59:56 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.4:49788) with ID 0,  ResourceProfileId 0
[2022-03-19 03:59:56,214] {spark_submit.py:488} INFO - 22/03/19 03:59:56 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.3:49740) with ID 1,  ResourceProfileId 0
[2022-03-19 03:59:56,437] {spark_submit.py:488} INFO - 22/03/19 03:59:56 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.4:43771 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.4, 43771, None)
[2022-03-19 03:59:56,440] {spark_submit.py:488} INFO - 22/03/19 03:59:56 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.3:45759 with 1048.8 MiB RAM, BlockManagerId(1, 172.18.0.3, 45759, None)
[2022-03-19 03:59:57,890] {spark_submit.py:488} INFO - 
[2022-03-19 03:59:57,966] {spark_submit.py:488} INFO - 16384/102967424 [..............................] - ETA: 9s
[2022-03-19 03:59:58,025] {spark_submit.py:488} INFO - 24576/102967424 [..............................] - ETA: 5:26
[2022-03-19 03:59:58,079] {spark_submit.py:488} INFO - 65536/102967424 [..............................] - ETA: 3:34
[2022-03-19 03:59:58,131] {spark_submit.py:488} INFO - 147456/102967424 [..............................] - ETA: 2:13
[2022-03-19 03:59:58,182] {spark_submit.py:488} INFO - 245760/102967424 [..............................] - ETA: 1:41
[2022-03-19 03:59:58,239] {spark_submit.py:488} INFO - 442368/102967424 [..............................] - ETA: 1:08
[2022-03-19 03:59:58,291] {spark_submit.py:488} INFO - 655360/102967424 [..............................] - ETA: 54s 
[2022-03-19 03:59:58,351] {spark_submit.py:488} INFO - 974848/102967424 [..............................] - ETA: 42s
[2022-03-19 03:59:58,402] {spark_submit.py:488} INFO - 1277952/102967424 [..............................] - ETA: 36s
[2022-03-19 03:59:58,618] {spark_submit.py:488} INFO - 1622016/102967424 [..............................] - ETA: 32s
[2022-03-19 03:59:58,771] {spark_submit.py:488} INFO - 1802240/102967424 [..............................] - ETA: 40s
[2022-03-19 03:59:58,821] {spark_submit.py:488} INFO - 1867776/102967424 [..............................] - ETA: 47s
[2022-03-19 03:59:58,971] {spark_submit.py:488} INFO - 2375680/102967424 [..............................] - ETA: 39s
[2022-03-19 03:59:59,024] {spark_submit.py:488} INFO - 2965504/102967424 [..............................] - ETA: 36s
[2022-03-19 03:59:59,126] {spark_submit.py:488} INFO - 4128768/102967424 [>.............................] - ETA: 27s
[2022-03-19 03:59:59,242] {spark_submit.py:488} INFO - 5103616/102967424 [>.............................] - ETA: 23s
[2022-03-19 03:59:59,296] {spark_submit.py:488} INFO - 5709824/102967424 [>.............................] - ETA: 23s
[2022-03-19 03:59:59,378] {spark_submit.py:488} INFO - 5988352/102967424 [>.............................] - ETA: 22s
[2022-03-19 03:59:59,432] {spark_submit.py:488} INFO - 6512640/102967424 [>.............................] - ETA: 22s
[2022-03-19 03:59:59,486] {spark_submit.py:488} INFO - 6725632/102967424 [>.............................] - ETA: 22s
[2022-03-19 03:59:59,567] {spark_submit.py:488} INFO - 7233536/102967424 [=>............................] - ETA: 21s
[2022-03-19 03:59:59,618] {spark_submit.py:488} INFO - 7282688/102967424 [=>............................] - ETA: 22s
[2022-03-19 03:59:59,785] {spark_submit.py:488} INFO - 7839744/102967424 [=>............................] - ETA: 20s
[2022-03-19 03:59:59,840] {spark_submit.py:488} INFO - 7987200/102967424 [=>............................] - ETA: 22s
[2022-03-19 03:59:59,904] {spark_submit.py:488} INFO - 8626176/102967424 [=>............................] - ETA: 21s
[2022-03-19 03:59:59,992] {spark_submit.py:488} INFO - 8658944/102967424 [=>............................] - ETA: 21s
[2022-03-19 04:00:00,043] {spark_submit.py:488} INFO - 8921088/102967424 [=>............................] - ETA: 22s
[2022-03-19 04:00:00,111] {spark_submit.py:488} INFO - 9068544/102967424 [=>............................] - ETA: 22s
[2022-03-19 04:00:00,162] {spark_submit.py:488} INFO - 9265152/102967424 [=>............................] - ETA: 22s
[2022-03-19 04:00:00,225] {spark_submit.py:488} INFO - 9527296/102967424 [=>............................] - ETA: 22s
[2022-03-19 04:00:00,388] {spark_submit.py:488} INFO - 9936896/102967424 [=>............................] - ETA: 21s
[2022-03-19 04:00:00,461] {spark_submit.py:488} INFO - 10608640/102967424 [==>...........................] - ETA: 21s
[2022-03-19 04:00:00,535] {spark_submit.py:488} INFO - 11067392/102967424 [==>...........................] - ETA: 21s
[2022-03-19 04:00:00,622] {spark_submit.py:488} INFO - 11362304/102967424 [==>...........................] - ETA: 21s
[2022-03-19 04:00:00,698] {spark_submit.py:488} INFO - 11673600/102967424 [==>...........................] - ETA: 21s
[2022-03-19 04:00:00,748] {spark_submit.py:488} INFO - 11984896/102967424 [==>...........................] - ETA: 21s
[2022-03-19 04:00:00,799] {spark_submit.py:488} INFO - 12492800/102967424 [==>...........................] - ETA: 20s
[2022-03-19 04:00:00,850] {spark_submit.py:488} INFO - 12705792/102967424 [==>...........................] - ETA: 20s
[2022-03-19 04:00:00,914] {spark_submit.py:488} INFO - 12918784/102967424 [==>...........................] - ETA: 20s
[2022-03-19 04:00:00,999] {spark_submit.py:488} INFO - 13197312/102967424 [==>...........................] - ETA: 20s
[2022-03-19 04:00:01,126] {spark_submit.py:488} INFO - 13312000/102967424 [==>...........................] - ETA: 20s
[2022-03-19 04:00:01,187] {spark_submit.py:488} INFO - 13721600/102967424 [==>...........................] - ETA: 21s
[2022-03-19 04:00:01,237] {spark_submit.py:488} INFO - 14213120/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:01,289] {spark_submit.py:488} INFO - 14540800/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:01,384] {spark_submit.py:488} INFO - 14917632/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:01,442] {spark_submit.py:488} INFO - 14966784/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:01,502] {spark_submit.py:488} INFO - 15196160/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:01,555] {spark_submit.py:488} INFO - 15409152/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:01,655] {spark_submit.py:488} INFO - 16048128/102967424 [===>..........................] - ETA: 19s
[2022-03-19 04:00:01,743] {spark_submit.py:488} INFO - 16244736/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:01,845] {spark_submit.py:488} INFO - 16310272/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:01,941] {spark_submit.py:488} INFO - 16359424/102967424 [===>..........................] - ETA: 20s
[2022-03-19 04:00:02,040] {spark_submit.py:488} INFO - 17522688/102967424 [====>.........................] - ETA: 19s
[2022-03-19 04:00:02,134] {spark_submit.py:488} INFO - 17653760/102967424 [====>.........................] - ETA: 20s
[2022-03-19 04:00:02,250] {spark_submit.py:488} INFO - 18309120/102967424 [====>.........................] - ETA: 19s
[2022-03-19 04:00:02,303] {spark_submit.py:488} INFO - 18898944/102967424 [====>.........................] - ETA: 19s
[2022-03-19 04:00:02,368] {spark_submit.py:488} INFO - 19324928/102967424 [====>.........................] - ETA: 19s
[2022-03-19 04:00:02,589] {spark_submit.py:488} INFO - 19537920/102967424 [====>.........................] - ETA: 19s
[2022-03-19 04:00:02,708] {spark_submit.py:488} INFO - 19636224/102967424 [====>.........................] - ETA: 19s
[2022-03-19 04:00:02,855] {spark_submit.py:488} INFO - 20127744/102967424 [====>.........................] - ETA: 19s
[2022-03-19 04:00:02,983] {spark_submit.py:488} INFO - 21127168/102967424 [=====>........................] - ETA: 19s
[2022-03-19 04:00:03,073] {spark_submit.py:488} INFO - 21995520/102967424 [=====>........................] - ETA: 18s
[2022-03-19 04:00:03,123] {spark_submit.py:488} INFO - 22585344/102967424 [=====>........................] - ETA: 18s
[2022-03-19 04:00:03,173] {spark_submit.py:488} INFO - 22880256/102967424 [=====>........................] - ETA: 18s
[2022-03-19 04:00:03,284] {spark_submit.py:488} INFO - 23207936/102967424 [=====>........................] - ETA: 18s
[2022-03-19 04:00:03,336] {spark_submit.py:488} INFO - 23355392/102967424 [=====>........................] - ETA: 18s
[2022-03-19 04:00:03,390] {spark_submit.py:488} INFO - 23617536/102967424 [=====>........................] - ETA: 18s
[2022-03-19 04:00:03,440] {spark_submit.py:488} INFO - 23830528/102967424 [=====>........................] - ETA: 18s
[2022-03-19 04:00:03,491] {spark_submit.py:488} INFO - 24289280/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:03,545] {spark_submit.py:488} INFO - 24469504/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:03,636] {spark_submit.py:488} INFO - 24633344/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:03,837] {spark_submit.py:488} INFO - 24715264/102967424 [======>.......................] - ETA: 18s
[2022-03-19 04:00:03,888] {spark_submit.py:488} INFO - 25255936/102967424 [======>.......................] - ETA: 18s
[2022-03-19 04:00:03,940] {spark_submit.py:488} INFO - 25911296/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:03,991] {spark_submit.py:488} INFO - 26157056/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:04,126] {spark_submit.py:488} INFO - 26451968/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:04,178] {spark_submit.py:488} INFO - 26681344/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:04,229] {spark_submit.py:488} INFO - 27172864/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:04,283] {spark_submit.py:488} INFO - 27418624/102967424 [======>.......................] - ETA: 17s
[2022-03-19 04:00:04,361] {spark_submit.py:488} INFO - 27615232/102967424 [=======>......................] - ETA: 17s
[2022-03-19 04:00:04,413] {spark_submit.py:488} INFO - 27631616/102967424 [=======>......................] - ETA: 17s
[2022-03-19 04:00:04,466] {spark_submit.py:488} INFO - 28286976/102967424 [=======>......................] - ETA: 17s
[2022-03-19 04:00:04,516] {spark_submit.py:488} INFO - 28549120/102967424 [=======>......................] - ETA: 17s
[2022-03-19 04:00:04,570] {spark_submit.py:488} INFO - 28762112/102967424 [=======>......................] - ETA: 17s
[2022-03-19 04:00:04,628] {spark_submit.py:488} INFO - 29024256/102967424 [=======>......................] - ETA: 17s
[2022-03-19 04:00:04,830] {spark_submit.py:488} INFO - 29220864/102967424 [=======>......................] - ETA: 17s
[2022-03-19 04:00:04,939] {spark_submit.py:488} INFO - 29433856/102967424 [=======>......................] - ETA: 17s
[2022-03-19 04:00:05,026] {spark_submit.py:488} INFO - 30547968/102967424 [=======>......................] - ETA: 16s
[2022-03-19 04:00:05,122] {spark_submit.py:488} INFO - 31006720/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,176] {spark_submit.py:488} INFO - 31236096/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,227] {spark_submit.py:488} INFO - 31481856/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,282] {spark_submit.py:488} INFO - 31694848/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,332] {spark_submit.py:488} INFO - 31989760/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,401] {spark_submit.py:488} INFO - 32284672/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,503] {spark_submit.py:488} INFO - 32514048/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,553] {spark_submit.py:488} INFO - 32612352/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,659] {spark_submit.py:488} INFO - 33333248/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,723] {spark_submit.py:488} INFO - 33497088/102967424 [========>.....................] - ETA: 16s
[2022-03-19 04:00:05,780] {spark_submit.py:488} INFO - 34217984/102967424 [========>.....................] - ETA: 15s
[2022-03-19 04:00:05,877] {spark_submit.py:488} INFO - 34512896/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:05,951] {spark_submit.py:488} INFO - 34611200/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,001] {spark_submit.py:488} INFO - 34742272/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,108] {spark_submit.py:488} INFO - 35512320/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,166] {spark_submit.py:488} INFO - 35725312/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,297] {spark_submit.py:488} INFO - 35987456/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,371] {spark_submit.py:488} INFO - 36265984/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,447] {spark_submit.py:488} INFO - 36610048/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,509] {spark_submit.py:488} INFO - 37232640/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,559] {spark_submit.py:488} INFO - 37429248/102967424 [=========>....................] - ETA: 15s
[2022-03-19 04:00:06,661] {spark_submit.py:488} INFO - 37871616/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:06,743] {spark_submit.py:488} INFO - 38002688/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:06,793] {spark_submit.py:488} INFO - 38543360/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:06,862] {spark_submit.py:488} INFO - 38854656/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:06,956] {spark_submit.py:488} INFO - 39067648/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:07,012] {spark_submit.py:488} INFO - 39182336/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:07,063] {spark_submit.py:488} INFO - 39952384/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:07,168] {spark_submit.py:488} INFO - 40198144/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:07,218] {spark_submit.py:488} INFO - 40378368/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:07,287] {spark_submit.py:488} INFO - 40607744/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:07,378] {spark_submit.py:488} INFO - 40689664/102967424 [==========>...................] - ETA: 14s
[2022-03-19 04:00:07,493] {spark_submit.py:488} INFO - 41328640/102967424 [===========>..................] - ETA: 14s
[2022-03-19 04:00:07,567] {spark_submit.py:488} INFO - 41525248/102967424 [===========>..................] - ETA: 14s
[2022-03-19 04:00:07,618] {spark_submit.py:488} INFO - 42115072/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:07,677] {spark_submit.py:488} INFO - 42426368/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:07,777] {spark_submit.py:488} INFO - 42803200/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:07,828] {spark_submit.py:488} INFO - 42934272/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:07,924] {spark_submit.py:488} INFO - 43196416/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:07,991] {spark_submit.py:488} INFO - 43524096/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:08,046] {spark_submit.py:488} INFO - 43900928/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:08,101] {spark_submit.py:488} INFO - 44408832/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:08,187] {spark_submit.py:488} INFO - 44605440/102967424 [===========>..................] - ETA: 13s
[2022-03-19 04:00:08,268] {spark_submit.py:488} INFO - 44703744/102967424 [============>.................] - ETA: 13s
[2022-03-19 04:00:08,406] {spark_submit.py:488} INFO - 45146112/102967424 [============>.................] - ETA: 13s
[2022-03-19 04:00:08,459] {spark_submit.py:488} INFO - 45539328/102967424 [============>.................] - ETA: 13s
[2022-03-19 04:00:08,525] {spark_submit.py:488} INFO - 46211072/102967424 [============>.................] - ETA: 12s
[2022-03-19 04:00:08,627] {spark_submit.py:488} INFO - 46276608/102967424 [============>.................] - ETA: 13s
[2022-03-19 04:00:08,682] {spark_submit.py:488} INFO - 46686208/102967424 [============>.................] - ETA: 12s
[2022-03-19 04:00:08,738] {spark_submit.py:488} INFO - 47112192/102967424 [============>.................] - ETA: 12s
[2022-03-19 04:00:08,813] {spark_submit.py:488} INFO - 47325184/102967424 [============>.................] - ETA: 12s
[2022-03-19 04:00:08,864] {spark_submit.py:488} INFO - 47423488/102967424 [============>.................] - ETA: 12s
[2022-03-19 04:00:08,958] {spark_submit.py:488} INFO - 47751168/102967424 [============>.................] - ETA: 12s
[2022-03-19 04:00:09,010] {spark_submit.py:488} INFO - 48160768/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,121] {spark_submit.py:488} INFO - 48439296/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,203] {spark_submit.py:488} INFO - 48832512/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,260] {spark_submit.py:488} INFO - 49176576/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,371] {spark_submit.py:488} INFO - 49586176/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,427] {spark_submit.py:488} INFO - 49848320/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,501] {spark_submit.py:488} INFO - 50126848/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,551] {spark_submit.py:488} INFO - 50438144/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,659] {spark_submit.py:488} INFO - 50831360/102967424 [=============>................] - ETA: 11s
[2022-03-19 04:00:09,755] {spark_submit.py:488} INFO - 50946048/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,844] {spark_submit.py:488} INFO - 51027968/102967424 [=============>................] - ETA: 12s
[2022-03-19 04:00:09,945] {spark_submit.py:488} INFO - 51863552/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,010] {spark_submit.py:488} INFO - 52191232/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,084] {spark_submit.py:488} INFO - 52486144/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,135] {spark_submit.py:488} INFO - 52781056/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,203] {spark_submit.py:488} INFO - 53370880/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,253] {spark_submit.py:488} INFO - 53387264/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,306] {spark_submit.py:488} INFO - 53649408/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,361] {spark_submit.py:488} INFO - 53960704/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,499] {spark_submit.py:488} INFO - 54255616/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,596] {spark_submit.py:488} INFO - 54403072/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,681] {spark_submit.py:488} INFO - 54829056/102967424 [==============>...............] - ETA: 11s
[2022-03-19 04:00:10,751] {spark_submit.py:488} INFO - 55549952/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:10,824] {spark_submit.py:488} INFO - 55779328/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:10,882] {spark_submit.py:488} INFO - 56107008/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:10,985] {spark_submit.py:488} INFO - 56221696/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:11,045] {spark_submit.py:488} INFO - 56680448/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:11,126] {spark_submit.py:488} INFO - 57253888/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:11,197] {spark_submit.py:488} INFO - 57335808/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:11,254] {spark_submit.py:488} INFO - 57663488/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:11,309] {spark_submit.py:488} INFO - 58187776/102967424 [===============>..............] - ETA: 10s
[2022-03-19 04:00:11,362] {spark_submit.py:488} INFO - 58417152/102967424 [================>.............] - ETA: 10s
[2022-03-19 04:00:11,432] {spark_submit.py:488} INFO - 58712064/102967424 [================>.............] - ETA: 10s
[2022-03-19 04:00:11,528] {spark_submit.py:488} INFO - 58728448/102967424 [================>.............] - ETA: 10s
[2022-03-19 04:00:11,583] {spark_submit.py:488} INFO - 59121664/102967424 [================>.............] - ETA: 10s
[2022-03-19 04:00:11,638] {spark_submit.py:488} INFO - 59678720/102967424 [================>.............] - ETA: 9s 
[2022-03-19 04:00:11,744] {spark_submit.py:488} INFO - 59875328/102967424 [================>.............] - ETA: 9s
[2022-03-19 04:00:11,802] {spark_submit.py:488} INFO - 59940864/102967424 [================>.............] - ETA: 9s
[2022-03-19 04:00:11,905] {spark_submit.py:488} INFO - 60547072/102967424 [================>.............] - ETA: 9s
[2022-03-19 04:00:11,965] {spark_submit.py:488} INFO - 60628992/102967424 [================>.............] - ETA: 9s
[2022-03-19 04:00:12,017] {spark_submit.py:488} INFO - 60923904/102967424 [================>.............] - ETA: 9s
[2022-03-19 04:00:12,132] {spark_submit.py:488} INFO - 61546496/102967424 [================>.............] - ETA: 9s
[2022-03-19 04:00:12,236] {spark_submit.py:488} INFO - 61792256/102967424 [=================>............] - ETA: 9s
[2022-03-19 04:00:12,342] {spark_submit.py:488} INFO - 62332928/102967424 [=================>............] - ETA: 9s
[2022-03-19 04:00:12,393] {spark_submit.py:488} INFO - 62758912/102967424 [=================>............] - ETA: 9s
[2022-03-19 04:00:12,475] {spark_submit.py:488} INFO - 63283200/102967424 [=================>............] - ETA: 9s
[2022-03-19 04:00:12,529] {spark_submit.py:488} INFO - 63381504/102967424 [=================>............] - ETA: 9s
[2022-03-19 04:00:12,580] {spark_submit.py:488} INFO - 63627264/102967424 [=================>............] - ETA: 9s
[2022-03-19 04:00:12,631] {spark_submit.py:488} INFO - 64069632/102967424 [=================>............] - ETA: 8s
[2022-03-19 04:00:12,729] {spark_submit.py:488} INFO - 64331776/102967424 [=================>............] - ETA: 8s
[2022-03-19 04:00:12,816] {spark_submit.py:488} INFO - 64544768/102967424 [=================>............] - ETA: 8s
[2022-03-19 04:00:12,926] {spark_submit.py:488} INFO - 64610304/102967424 [=================>............] - ETA: 8s
[2022-03-19 04:00:13,014] {spark_submit.py:488} INFO - 65282048/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,083] {spark_submit.py:488} INFO - 65593344/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,146] {spark_submit.py:488} INFO - 65871872/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,200] {spark_submit.py:488} INFO - 66052096/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,254] {spark_submit.py:488} INFO - 66215936/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,308] {spark_submit.py:488} INFO - 66560000/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,358] {spark_submit.py:488} INFO - 66805760/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,450] {spark_submit.py:488} INFO - 67100672/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,539] {spark_submit.py:488} INFO - 67248128/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,604] {spark_submit.py:488} INFO - 67706880/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,657] {spark_submit.py:488} INFO - 68182016/102967424 [==================>...........] - ETA: 8s
[2022-03-19 04:00:13,716] {spark_submit.py:488} INFO - 68329472/102967424 [==================>...........] - ETA: 7s
[2022-03-19 04:00:13,767] {spark_submit.py:488} INFO - 68460544/102967424 [==================>...........] - ETA: 7s
[2022-03-19 04:00:13,819] {spark_submit.py:488} INFO - 68608000/102967424 [==================>...........] - ETA: 7s
[2022-03-19 04:00:13,871] {spark_submit.py:488} INFO - 68837376/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:13,925] {spark_submit.py:488} INFO - 69099520/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:13,977] {spark_submit.py:488} INFO - 69328896/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,028] {spark_submit.py:488} INFO - 69640192/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,084] {spark_submit.py:488} INFO - 69967872/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,133] {spark_submit.py:488} INFO - 70213632/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,186] {spark_submit.py:488} INFO - 70623232/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,259] {spark_submit.py:488} INFO - 70950912/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,379] {spark_submit.py:488} INFO - 71065600/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,453] {spark_submit.py:488} INFO - 71311360/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,539] {spark_submit.py:488} INFO - 71753728/102967424 [===================>..........] - ETA: 7s
[2022-03-19 04:00:14,602] {spark_submit.py:488} INFO - 72097792/102967424 [====================>.........] - ETA: 7s
[2022-03-19 04:00:14,653] {spark_submit.py:488} INFO - 72146944/102967424 [====================>.........] - ETA: 7s
[2022-03-19 04:00:14,710] {spark_submit.py:488} INFO - 72802304/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:14,761] {spark_submit.py:488} INFO - 73211904/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:14,943] {spark_submit.py:488} INFO - 73441280/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:14,993] {spark_submit.py:488} INFO - 73555968/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:15,054] {spark_submit.py:488} INFO - 73932800/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:15,131] {spark_submit.py:488} INFO - 74489856/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:15,181] {spark_submit.py:488} INFO - 74752000/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:15,276] {spark_submit.py:488} INFO - 75153408/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:15,395] {spark_submit.py:488} INFO - 75341824/102967424 [====================>.........] - ETA: 6s
[2022-03-19 04:00:15,449] {spark_submit.py:488} INFO - 75718656/102967424 [=====================>........] - ETA: 6s
[2022-03-19 04:00:15,505] {spark_submit.py:488} INFO - 75898880/102967424 [=====================>........] - ETA: 6s
[2022-03-19 04:00:15,565] {spark_submit.py:488} INFO - 76292096/102967424 [=====================>........] - ETA: 6s
[2022-03-19 04:00:15,617] {spark_submit.py:488} INFO - 76554240/102967424 [=====================>........] - ETA: 6s
[2022-03-19 04:00:15,676] {spark_submit.py:488} INFO - 76750848/102967424 [=====================>........] - ETA: 6s
[2022-03-19 04:00:15,728] {spark_submit.py:488} INFO - 77062144/102967424 [=====================>........] - ETA: 5s
[2022-03-19 04:00:15,780] {spark_submit.py:488} INFO - 77291520/102967424 [=====================>........] - ETA: 5s
[2022-03-19 04:00:15,831] {spark_submit.py:488} INFO - 77553664/102967424 [=====================>........] - ETA: 5s
[2022-03-19 04:00:15,964] {spark_submit.py:488} INFO - 77783040/102967424 [=====================>........] - ETA: 5s
[2022-03-19 04:00:16,095] {spark_submit.py:488} INFO - 77914112/102967424 [=====================>........] - ETA: 5s
[2022-03-19 04:00:16,153] {spark_submit.py:488} INFO - 78716928/102967424 [=====================>........] - ETA: 5s
[2022-03-19 04:00:16,247] {spark_submit.py:488} INFO - 79044608/102967424 [======================>.......] - ETA: 5s
[2022-03-19 04:00:16,297] {spark_submit.py:488} INFO - 79454208/102967424 [======================>.......] - ETA: 5s
[2022-03-19 04:00:16,359] {spark_submit.py:488} INFO - 79921152/102967424 [======================>.......] - ETA: 5s
[2022-03-19 04:00:16,409] {spark_submit.py:488} INFO - 80060416/102967424 [======================>.......] - ETA: 5s
[2022-03-19 04:00:16,523] {spark_submit.py:488} INFO - 80257024/102967424 [======================>.......] - ETA: 5s
[2022-03-19 04:00:16,588] {spark_submit.py:488} INFO - 80814080/102967424 [======================>.......] - ETA: 5s
[2022-03-19 04:00:16,685] {spark_submit.py:488} INFO - 80863232/102967424 [======================>.......] - ETA: 5s
[2022-03-19 04:00:16,770] {spark_submit.py:488} INFO - 81616896/102967424 [======================>.......] - ETA: 4s
[2022-03-19 04:00:16,825] {spark_submit.py:488} INFO - 82059264/102967424 [======================>.......] - ETA: 4s
[2022-03-19 04:00:16,875] {spark_submit.py:488} INFO - 82337792/102967424 [======================>.......] - ETA: 4s
[2022-03-19 04:00:16,926] {spark_submit.py:488} INFO - 82550784/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:16,989] {spark_submit.py:488} INFO - 82763776/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,101] {spark_submit.py:488} INFO - 82993152/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,152] {spark_submit.py:488} INFO - 83238912/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,207] {spark_submit.py:488} INFO - 83550208/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,303] {spark_submit.py:488} INFO - 84107264/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,355] {spark_submit.py:488} INFO - 84254720/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,406] {spark_submit.py:488} INFO - 84484096/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,511] {spark_submit.py:488} INFO - 84779008/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,571] {spark_submit.py:488} INFO - 84942848/102967424 [=======================>......] - ETA: 4s
[2022-03-19 04:00:17,642] {spark_submit.py:488} INFO - 85630976/102967424 [=======================>......] - ETA: 3s
[2022-03-19 04:00:17,695] {spark_submit.py:488} INFO - 85680128/102967424 [=======================>......] - ETA: 3s
[2022-03-19 04:00:17,745] {spark_submit.py:488} INFO - 86204416/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:17,804] {spark_submit.py:488} INFO - 86417408/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:17,857] {spark_submit.py:488} INFO - 86695936/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,034] {spark_submit.py:488} INFO - 86908928/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,085] {spark_submit.py:488} INFO - 87040000/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,137] {spark_submit.py:488} INFO - 87842816/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,198] {spark_submit.py:488} INFO - 88006656/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,269] {spark_submit.py:488} INFO - 88170496/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,323] {spark_submit.py:488} INFO - 88481792/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,385] {spark_submit.py:488} INFO - 88776704/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,464] {spark_submit.py:488} INFO - 89022464/102967424 [========================>.....] - ETA: 3s
[2022-03-19 04:00:18,572] {spark_submit.py:488} INFO - 89317376/102967424 [=========================>....] - ETA: 3s
[2022-03-19 04:00:18,622] {spark_submit.py:488} INFO - 89710592/102967424 [=========================>....] - ETA: 3s
[2022-03-19 04:00:18,674] {spark_submit.py:488} INFO - 90185728/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:18,743] {spark_submit.py:488} INFO - 90447872/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:18,795] {spark_submit.py:488} INFO - 90464256/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:18,869] {spark_submit.py:488} INFO - 90775552/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:18,924] {spark_submit.py:488} INFO - 91037696/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:18,974] {spark_submit.py:488} INFO - 91332608/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:19,100] {spark_submit.py:488} INFO - 91447296/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:19,209] {spark_submit.py:488} INFO - 91578368/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:19,318] {spark_submit.py:488} INFO - 92151808/102967424 [=========================>....] - ETA: 2s
[2022-03-19 04:00:19,372] {spark_submit.py:488} INFO - 92741632/102967424 [==========================>...] - ETA: 2s
[2022-03-19 04:00:19,482] {spark_submit.py:488} INFO - 93036544/102967424 [==========================>...] - ETA: 2s
[2022-03-19 04:00:19,578] {spark_submit.py:488} INFO - 93593600/102967424 [==========================>...] - ETA: 2s
[2022-03-19 04:00:19,634] {spark_submit.py:488} INFO - 94117888/102967424 [==========================>...] - ETA: 2s
[2022-03-19 04:00:19,719] {spark_submit.py:488} INFO - 94461952/102967424 [==========================>...] - ETA: 1s
[2022-03-19 04:00:19,822] {spark_submit.py:488} INFO - 94494720/102967424 [==========================>...] - ETA: 1s
[2022-03-19 04:00:19,876] {spark_submit.py:488} INFO - 94707712/102967424 [==========================>...] - ETA: 1s
[2022-03-19 04:00:19,968] {spark_submit.py:488} INFO - 95657984/102967424 [==========================>...] - ETA: 1s
[2022-03-19 04:00:20,099] {spark_submit.py:488} INFO - 95707136/102967424 [==========================>...] - ETA: 1s
[2022-03-19 04:00:20,169] {spark_submit.py:488} INFO - 96051200/102967424 [==========================>...] - ETA: 1s
[2022-03-19 04:00:20,266] {spark_submit.py:488} INFO - 96116736/102967424 [===========================>..] - ETA: 1s
[2022-03-19 04:00:20,317] {spark_submit.py:488} INFO - 96722944/102967424 [===========================>..] - ETA: 1s
[2022-03-19 04:00:20,374] {spark_submit.py:488} INFO - 97296384/102967424 [===========================>..] - ETA: 1s
[2022-03-19 04:00:20,426] {spark_submit.py:488} INFO - 97656832/102967424 [===========================>..] - ETA: 1s
[2022-03-19 04:00:20,601] {spark_submit.py:488} INFO - 98115584/102967424 [===========================>..] - ETA: 1s
[2022-03-19 04:00:20,660] {spark_submit.py:488} INFO - 98361344/102967424 [===========================>..] - ETA: 1s
[2022-03-19 04:00:20,721] {spark_submit.py:488} INFO - 98377728/102967424 [===========================>..] - ETA: 1s
[2022-03-19 04:00:20,789] {spark_submit.py:488} INFO - 98934784/102967424 [===========================>..] - ETA: 0s
[2022-03-19 04:00:20,849] {spark_submit.py:488} INFO - 99426304/102967424 [===========================>..] - ETA: 0s
[2022-03-19 04:00:20,900] {spark_submit.py:488} INFO - 99639296/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,002] {spark_submit.py:488} INFO - 100098048/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,052] {spark_submit.py:488} INFO - 100294656/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,118] {spark_submit.py:488} INFO - 100663296/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,172] {spark_submit.py:488} INFO - 100868096/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,262] {spark_submit.py:488} INFO - 101310464/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,402] {spark_submit.py:488} INFO - 101392384/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,533] {spark_submit.py:488} INFO - 101736448/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,588] {spark_submit.py:488} INFO - 102490112/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,592] {spark_submit.py:488} INFO - 102735872/102967424 [============================>.] - ETA: 0s
[2022-03-19 04:00:21,593] {spark_submit.py:488} INFO - 102973440/102967424 [==============================] - 24s 0us/step
[2022-03-19 04:00:21,593] {spark_submit.py:488} INFO - 
[2022-03-19 04:00:21,594] {spark_submit.py:488} INFO - 102981632/102967424 [==============================] - 24s 0us/step
[2022-03-19 04:00:22,062] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 208.0 B, free 434.4 MiB)
[2022-03-19 04:00:22,300] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 430.4 MiB)
[2022-03-19 04:00:22,304] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 430.4 MiB)
[2022-03-19 04:00:22,313] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 426.4 MiB)
[2022-03-19 04:00:22,314] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece1 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 426.4 MiB)
[2022-03-19 04:00:22,318] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 422.4 MiB)
[2022-03-19 04:00:22,319] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece2 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 422.4 MiB)
[2022-03-19 04:00:22,322] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 418.4 MiB)
[2022-03-19 04:00:22,323] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece3 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 418.4 MiB)
[2022-03-19 04:00:22,326] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece4 stored as bytes in memory (estimated size 4.0 MiB, free 414.4 MiB)
[2022-03-19 04:00:22,327] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece4 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 414.4 MiB)
[2022-03-19 04:00:22,329] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece5 stored as bytes in memory (estimated size 4.0 MiB, free 410.4 MiB)
[2022-03-19 04:00:22,330] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece5 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 410.4 MiB)
[2022-03-19 04:00:22,333] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece6 stored as bytes in memory (estimated size 4.0 MiB, free 406.4 MiB)
[2022-03-19 04:00:22,334] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece6 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 406.4 MiB)
[2022-03-19 04:00:22,336] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece7 stored as bytes in memory (estimated size 4.0 MiB, free 402.4 MiB)
[2022-03-19 04:00:22,337] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece7 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 402.4 MiB)
[2022-03-19 04:00:22,339] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece8 stored as bytes in memory (estimated size 4.0 MiB, free 398.4 MiB)
[2022-03-19 04:00:22,340] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece8 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 398.4 MiB)
[2022-03-19 04:00:22,342] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece9 stored as bytes in memory (estimated size 4.0 MiB, free 394.4 MiB)
[2022-03-19 04:00:22,343] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece9 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 394.4 MiB)
[2022-03-19 04:00:22,346] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece10 stored as bytes in memory (estimated size 4.0 MiB, free 390.4 MiB)
[2022-03-19 04:00:22,347] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece10 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 390.4 MiB)
[2022-03-19 04:00:22,349] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece11 stored as bytes in memory (estimated size 4.0 MiB, free 386.4 MiB)
[2022-03-19 04:00:22,350] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece11 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 386.4 MiB)
[2022-03-19 04:00:22,352] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece12 stored as bytes in memory (estimated size 4.0 MiB, free 382.4 MiB)
[2022-03-19 04:00:22,353] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece12 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 382.4 MiB)
[2022-03-19 04:00:22,356] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece13 stored as bytes in memory (estimated size 4.0 MiB, free 378.4 MiB)
[2022-03-19 04:00:22,356] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece13 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 378.4 MiB)
[2022-03-19 04:00:22,359] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece14 stored as bytes in memory (estimated size 4.0 MiB, free 374.4 MiB)
[2022-03-19 04:00:22,359] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece14 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 374.4 MiB)
[2022-03-19 04:00:22,362] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece15 stored as bytes in memory (estimated size 4.0 MiB, free 370.4 MiB)
[2022-03-19 04:00:22,362] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece15 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 370.4 MiB)
[2022-03-19 04:00:22,364] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece16 stored as bytes in memory (estimated size 4.0 MiB, free 366.4 MiB)
[2022-03-19 04:00:22,365] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece16 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 366.4 MiB)
[2022-03-19 04:00:22,368] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece17 stored as bytes in memory (estimated size 4.0 MiB, free 362.4 MiB)
[2022-03-19 04:00:22,369] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece17 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 362.4 MiB)
[2022-03-19 04:00:22,371] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece18 stored as bytes in memory (estimated size 4.0 MiB, free 358.4 MiB)
[2022-03-19 04:00:22,372] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece18 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 358.4 MiB)
[2022-03-19 04:00:22,374] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece19 stored as bytes in memory (estimated size 4.0 MiB, free 354.4 MiB)
[2022-03-19 04:00:22,375] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece19 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 354.4 MiB)
[2022-03-19 04:00:22,377] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece20 stored as bytes in memory (estimated size 4.0 MiB, free 350.4 MiB)
[2022-03-19 04:00:22,378] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece20 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 350.4 MiB)
[2022-03-19 04:00:22,380] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece21 stored as bytes in memory (estimated size 4.0 MiB, free 346.4 MiB)
[2022-03-19 04:00:22,381] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece21 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 346.4 MiB)
[2022-03-19 04:00:22,383] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece22 stored as bytes in memory (estimated size 4.0 MiB, free 342.4 MiB)
[2022-03-19 04:00:22,384] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece22 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 342.4 MiB)
[2022-03-19 04:00:22,387] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece23 stored as bytes in memory (estimated size 4.0 MiB, free 338.4 MiB)
[2022-03-19 04:00:22,387] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece23 in memory on 616fa5651a96:32785 (size: 4.0 MiB, free: 338.4 MiB)
[2022-03-19 04:00:22,389] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO MemoryStore: Block broadcast_0_piece24 stored as bytes in memory (estimated size 2.2 MiB, free 336.2 MiB)
[2022-03-19 04:00:22,390] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO BlockManagerInfo: Added broadcast_0_piece24 in memory on 616fa5651a96:32785 (size: 2.2 MiB, free: 336.2 MiB)
[2022-03-19 04:00:22,392] {spark_submit.py:488} INFO - 22/03/19 04:00:22 INFO SparkContext: Created broadcast 0 from broadcast at NativeMethodAccessorImpl.java:0
[2022-03-19 04:00:23,509] {spark_submit.py:488} INFO - /usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/pandas/functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.
[2022-03-19 04:00:26,019] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO CodeGenerator: Code generated in 214.741792 ms
[2022-03-19 04:00:26,056] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-03-19 04:00:26,075] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-03-19 04:00:26,077] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)
[2022-03-19 04:00:26,078] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO DAGScheduler: Parents of final stage: List()
[2022-03-19 04:00:26,079] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO DAGScheduler: Missing parents: List()
[2022-03-19 04:00:26,082] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-03-19 04:00:26,134] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.8 KiB, free 336.1 MiB)
[2022-03-19 04:00:26,159] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 336.1 MiB)
[2022-03-19 04:00:26,161] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 616fa5651a96:32785 (size: 6.2 KiB, free: 336.1 MiB)
[2022-03-19 04:00:26,174] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
[2022-03-19 04:00:26,207] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-03-19 04:00:26,208] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2022-03-19 04:00:26,264] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.3, executor 1, partition 0, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()
[2022-03-19 04:00:26,538] {spark_submit.py:488} INFO - 22/03/19 04:00:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.3:45759 (size: 6.2 KiB, free: 1048.8 MiB)
[2022-03-19 04:00:27,813] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1561 ms on 172.18.0.3 (executor 1) (1/1)
[2022-03-19 04:00:27,817] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2022-03-19 04:00:27,827] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 39841
[2022-03-19 04:00:27,833] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 1.736 s
[2022-03-19 04:00:27,838] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-03-19 04:00:27,839] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2022-03-19 04:00:27,841] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 1.784130 s
[2022-03-19 04:00:27,857] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-03-19 04:00:27,859] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 3 output partitions
[2022-03-19 04:00:27,860] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)
[2022-03-19 04:00:27,861] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: Parents of final stage: List()
[2022-03-19 04:00:27,862] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: Missing parents: List()
[2022-03-19 04:00:27,863] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-03-19 04:00:27,869] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.8 KiB, free 336.1 MiB)
[2022-03-19 04:00:27,883] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 336.1 MiB)
[2022-03-19 04:00:27,885] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 616fa5651a96:32785 (size: 6.2 KiB, free: 336.1 MiB)
[2022-03-19 04:00:27,887] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1478
[2022-03-19 04:00:27,888] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(1, 2, 3))
[2022-03-19 04:00:27,890] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks resource profile 0
[2022-03-19 04:00:27,892] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.3, executor 1, partition 1, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()
[2022-03-19 04:00:27,893] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()
[2022-03-19 04:00:27,894] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.3, executor 1, partition 3, PROCESS_LOCAL, 4755 bytes) taskResourceAssignments Map()
[2022-03-19 04:00:27,938] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 616fa5651a96:32785 in memory (size: 6.2 KiB, free: 336.1 MiB)
[2022-03-19 04:00:27,973] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.3:45759 in memory (size: 6.2 KiB, free: 1048.8 MiB)
[2022-03-19 04:00:27,989] {spark_submit.py:488} INFO - 22/03/19 04:00:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.3:45759 (size: 6.2 KiB, free: 1048.8 MiB)
[2022-03-19 04:00:28,053] {spark_submit.py:488} INFO - 22/03/19 04:00:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 162 ms on 172.18.0.3 (executor 1) (1/3)
[2022-03-19 04:00:28,063] {spark_submit.py:488} INFO - 22/03/19 04:00:28 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 169 ms on 172.18.0.3 (executor 1) (2/3)
[2022-03-19 04:00:28,230] {spark_submit.py:488} INFO - 22/03/19 04:00:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.4:43771 (size: 6.2 KiB, free: 1048.8 MiB)
[2022-03-19 04:00:29,446] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1554 ms on 172.18.0.4 (executor 0) (3/3)
[2022-03-19 04:00:29,450] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2022-03-19 04:00:29,452] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.586 s
[2022-03-19 04:00:29,453] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-03-19 04:00:29,455] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2022-03-19 04:00:29,455] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 1.595632 s
[2022-03-19 04:00:29,495] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO CodeGenerator: Code generated in 23.973092 ms
[2022-03-19 04:00:29,508] {spark_submit.py:488} INFO - +--------------------+-----+
[2022-03-19 04:00:29,508] {spark_submit.py:488} INFO - |             content|class|
[2022-03-19 04:00:29,509] {spark_submit.py:488} INFO - +--------------------+-----+
[2022-03-19 04:00:29,510] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,510] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,511] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,511] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,512] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,513] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,513] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,514] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,514] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,515] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,516] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,517] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,518] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,518] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,519] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,519] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,520] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,520] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,521] {spark_submit.py:488} INFO - |//usr/local/share...|  bee|
[2022-03-19 04:00:29,522] {spark_submit.py:488} INFO - |//usr/local/share...|  pot|
[2022-03-19 04:00:29,522] {spark_submit.py:488} INFO - +--------------------+-----+
[2022-03-19 04:00:29,523] {spark_submit.py:488} INFO - only showing top 20 rows
[2022-03-19 04:00:29,523] {spark_submit.py:488} INFO - 
[2022-03-19 04:00:29,524] {spark_submit.py:488} INFO - None
[2022-03-19 04:00:29,693] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO BaseAllocator: Debug mode disabled.
[2022-03-19 04:00:29,695] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DefaultAllocationManagerOption: allocation manager type not specified, using netty as the default type
[2022-03-19 04:00:29,696] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO CheckAllocator: Using DefaultAllocationManager at memory-netty-2.0.0.jar!/org/apache/arrow/memory/DefaultAllocationManagerFactory.class
[2022-03-19 04:00:29,761] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO CodeGenerator: Code generated in 17.038275 ms
[2022-03-19 04:00:29,813] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-03-19 04:00:29,816] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-03-19 04:00:29,818] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)
[2022-03-19 04:00:29,819] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: Parents of final stage: List()
[2022-03-19 04:00:29,820] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: Missing parents: List()
[2022-03-19 04:00:29,824] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-03-19 04:00:29,836] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 27.7 KiB, free 336.1 MiB)
[2022-03-19 04:00:29,861] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.2 KiB, free 336.1 MiB)
[2022-03-19 04:00:29,864] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 616fa5651a96:32785 (size: 13.2 KiB, free: 336.1 MiB)
[2022-03-19 04:00:29,866] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1478
[2022-03-19 04:00:29,868] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-03-19 04:00:29,870] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2022-03-19 04:00:29,873] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4) (172.18.0.3, executor 1, partition 0, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()
[2022-03-19 04:00:29,875] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 616fa5651a96:32785 in memory (size: 6.2 KiB, free: 336.1 MiB)
[2022-03-19 04:00:29,881] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.4:43771 in memory (size: 6.2 KiB, free: 1048.8 MiB)
[2022-03-19 04:00:29,883] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.3:45759 in memory (size: 6.2 KiB, free: 1048.8 MiB)
[2022-03-19 04:00:29,931] {spark_submit.py:488} INFO - 22/03/19 04:00:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.3:45759 (size: 13.2 KiB, free: 1048.8 MiB)
[2022-03-19 04:00:30,875] {spark_submit.py:488} INFO - 22/03/19 04:00:30 INFO BlockManagerInfo: Added broadcast_0_piece10 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1044.8 MiB)
[2022-03-19 04:00:30,933] {spark_submit.py:488} INFO - 22/03/19 04:00:30 INFO BlockManagerInfo: Added broadcast_0_piece19 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1040.8 MiB)
[2022-03-19 04:00:30,989] {spark_submit.py:488} INFO - 22/03/19 04:00:30 INFO BlockManagerInfo: Added broadcast_0_piece23 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1036.8 MiB)
[2022-03-19 04:00:31,012] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece5 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1032.8 MiB)
[2022-03-19 04:00:31,042] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece4 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1028.8 MiB)
[2022-03-19 04:00:31,072] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece17 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1024.8 MiB)
[2022-03-19 04:00:31,101] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece16 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1020.8 MiB)
[2022-03-19 04:00:31,151] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece12 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1016.8 MiB)
[2022-03-19 04:00:31,182] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece18 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1012.8 MiB)
[2022-03-19 04:00:31,202] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece3 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1008.8 MiB)
[2022-03-19 04:00:31,231] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece13 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1004.8 MiB)
[2022-03-19 04:00:31,262] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece1 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 1000.8 MiB)
[2022-03-19 04:00:31,296] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece15 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 996.8 MiB)
[2022-03-19 04:00:31,317] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece6 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 992.8 MiB)
[2022-03-19 04:00:31,346] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece14 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 988.8 MiB)
[2022-03-19 04:00:31,372] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece11 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 984.8 MiB)
[2022-03-19 04:00:31,401] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece8 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 980.8 MiB)
[2022-03-19 04:00:31,429] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece7 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 976.8 MiB)
[2022-03-19 04:00:31,449] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece24 in memory on 172.18.0.3:45759 (size: 2.2 MiB, free: 974.5 MiB)
[2022-03-19 04:00:31,470] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece2 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 970.5 MiB)
[2022-03-19 04:00:31,493] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece20 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 966.5 MiB)
[2022-03-19 04:00:31,519] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece9 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 962.5 MiB)
[2022-03-19 04:00:31,542] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece21 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 958.5 MiB)
[2022-03-19 04:00:31,561] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece22 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 954.5 MiB)
[2022-03-19 04:00:31,588] {spark_submit.py:488} INFO - 22/03/19 04:00:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.3:45759 (size: 4.0 MiB, free: 950.5 MiB)
[2022-03-19 04:00:32,348] {spark_submit.py:488} INFO - 22/03/19 04:00:32 INFO BlockManagerInfo: Added broadcast_0_python on disk on 172.18.0.3:45759 (size: 97.8 MiB)
[2022-03-19 04:00:32,717] {spark_submit.py:488} INFO - 22/03/19 04:00:32 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 4) (172.18.0.3 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
[2022-03-19 04:00:32,718] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 603, in main
[2022-03-19 04:00:32,719] {spark_submit.py:488} INFO - func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)
[2022-03-19 04:00:32,720] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 338, in read_udfs
[2022-03-19 04:00:32,720] {spark_submit.py:488} INFO - arg_offsets, udf = read_single_udf(
[2022-03-19 04:00:32,721] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 251, in read_single_udf
[2022-03-19 04:00:32,722] {spark_submit.py:488} INFO - f, return_type = read_command(pickleSer, infile)
[2022-03-19 04:00:32,723] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 71, in read_command
[2022-03-19 04:00:32,724] {spark_submit.py:488} INFO - command = serializer._read_with_length(file)
[2022-03-19 04:00:32,725] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 160, in _read_with_length
[2022-03-19 04:00:32,726] {spark_submit.py:488} INFO - return self.loads(obj)
[2022-03-19 04:00:32,727] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 430, in loads
[2022-03-19 04:00:32,728] {spark_submit.py:488} INFO - return pickle.loads(obj, encoding=encoding)
[2022-03-19 04:00:32,729] {spark_submit.py:488} INFO - ModuleNotFoundError: No module named 'keras'
[2022-03-19 04:00:32,730] {spark_submit.py:488} INFO - 
[2022-03-19 04:00:32,730] {spark_submit.py:488} INFO - at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)
[2022-03-19 04:00:32,731] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)
[2022-03-19 04:00:32,732] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)
[2022-03-19 04:00:32,732] {spark_submit.py:488} INFO - at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)
[2022-03-19 04:00:32,733] {spark_submit.py:488} INFO - at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
[2022-03-19 04:00:32,735] {spark_submit.py:488} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2022-03-19 04:00:32,735] {spark_submit.py:488} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2022-03-19 04:00:32,736] {spark_submit.py:488} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
[2022-03-19 04:00:32,737] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2022-03-19 04:00:32,738] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)
[2022-03-19 04:00:32,738] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)
[2022-03-19 04:00:32,739] {spark_submit.py:488} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
[2022-03-19 04:00:32,740] {spark_submit.py:488} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
[2022-03-19 04:00:32,740] {spark_submit.py:488} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2022-03-19 04:00:32,741] {spark_submit.py:488} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2022-03-19 04:00:32,742] {spark_submit.py:488} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2022-03-19 04:00:32,743] {spark_submit.py:488} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2022-03-19 04:00:32,743] {spark_submit.py:488} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2022-03-19 04:00:32,744] {spark_submit.py:488} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2022-03-19 04:00:32,745] {spark_submit.py:488} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
[2022-03-19 04:00:32,746] {spark_submit.py:488} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2022-03-19 04:00:32,746] {spark_submit.py:488} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2022-03-19 04:00:32,747] {spark_submit.py:488} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2022-03-19 04:00:32,748] {spark_submit.py:488} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2022-03-19 04:00:32,749] {spark_submit.py:488} INFO - 
[2022-03-19 04:00:32,751] {spark_submit.py:488} INFO - 22/03/19 04:00:32 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 5) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()
[2022-03-19 04:00:32,752] {spark_submit.py:488} INFO - 22/03/19 04:00:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.4:43771 (size: 13.2 KiB, free: 1048.8 MiB)
[2022-03-19 04:00:33,461] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece7 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1044.8 MiB)
[2022-03-19 04:00:33,552] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece1 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1040.8 MiB)
[2022-03-19 04:00:33,628] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece8 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1036.8 MiB)
[2022-03-19 04:00:33,652] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece18 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1032.8 MiB)
[2022-03-19 04:00:33,681] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece9 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1028.8 MiB)
[2022-03-19 04:00:33,708] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece5 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1024.8 MiB)
[2022-03-19 04:00:33,725] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece24 in memory on 172.18.0.4:43771 (size: 2.2 MiB, free: 1022.5 MiB)
[2022-03-19 04:00:33,746] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece10 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1018.5 MiB)
[2022-03-19 04:00:33,776] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece20 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1014.5 MiB)
[2022-03-19 04:00:33,804] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece3 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1010.5 MiB)
[2022-03-19 04:00:33,836] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece21 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1006.5 MiB)
[2022-03-19 04:00:33,872] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece16 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 1002.5 MiB)
[2022-03-19 04:00:33,901] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece12 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 998.5 MiB)
[2022-03-19 04:00:33,921] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece4 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 994.5 MiB)
[2022-03-19 04:00:33,948] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 990.5 MiB)
[2022-03-19 04:00:33,969] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece15 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 986.5 MiB)
[2022-03-19 04:00:33,999] {spark_submit.py:488} INFO - 22/03/19 04:00:33 INFO BlockManagerInfo: Added broadcast_0_piece14 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 982.5 MiB)
[2022-03-19 04:00:34,026] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_piece6 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 978.5 MiB)
[2022-03-19 04:00:34,059] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_piece23 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 974.5 MiB)
[2022-03-19 04:00:34,094] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_piece2 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 970.5 MiB)
[2022-03-19 04:00:34,121] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_piece11 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 966.5 MiB)
[2022-03-19 04:00:34,154] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_piece19 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 962.5 MiB)
[2022-03-19 04:00:34,185] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_piece17 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 958.5 MiB)
[2022-03-19 04:00:34,209] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_piece22 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 954.5 MiB)
[2022-03-19 04:00:34,232] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_piece13 in memory on 172.18.0.4:43771 (size: 4.0 MiB, free: 950.5 MiB)
[2022-03-19 04:00:34,875] {spark_submit.py:488} INFO - 22/03/19 04:00:34 INFO BlockManagerInfo: Added broadcast_0_python on disk on 172.18.0.4:43771 (size: 97.8 MiB)
[2022-03-19 04:00:35,191] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO TaskSetManager: Lost task 0.1 in stage 2.0 (TID 5) on 172.18.0.4, executor 0: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
[2022-03-19 04:00:35,192] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 603, in main
[2022-03-19 04:00:35,193] {spark_submit.py:488} INFO - func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)
[2022-03-19 04:00:35,195] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 338, in read_udfs
[2022-03-19 04:00:35,195] {spark_submit.py:488} INFO - arg_offsets, udf = read_single_udf(
[2022-03-19 04:00:35,196] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 251, in read_single_udf
[2022-03-19 04:00:35,197] {spark_submit.py:488} INFO - f, return_type = read_command(pickleSer, infile)
[2022-03-19 04:00:35,198] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 71, in read_command
[2022-03-19 04:00:35,199] {spark_submit.py:488} INFO - command = serializer._read_with_length(file)
[2022-03-19 04:00:35,200] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 160, in _read_with_length
[2022-03-19 04:00:35,201] {spark_submit.py:488} INFO - return self.loads(obj)
[2022-03-19 04:00:35,202] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 430, in loads
[2022-03-19 04:00:35,203] {spark_submit.py:488} INFO - return pickle.loads(obj, encoding=encoding)
[2022-03-19 04:00:35,203] {spark_submit.py:488} INFO - ModuleNotFoundError: No module named 'keras'
[2022-03-19 04:00:35,204] {spark_submit.py:488} INFO - ) [duplicate 1]
[2022-03-19 04:00:35,205] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO TaskSetManager: Starting task 0.2 in stage 2.0 (TID 6) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()
[2022-03-19 04:00:35,266] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO TaskSetManager: Lost task 0.2 in stage 2.0 (TID 6) on 172.18.0.4, executor 0: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
[2022-03-19 04:00:35,267] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 603, in main
[2022-03-19 04:00:35,268] {spark_submit.py:488} INFO - func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)
[2022-03-19 04:00:35,269] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 338, in read_udfs
[2022-03-19 04:00:35,270] {spark_submit.py:488} INFO - arg_offsets, udf = read_single_udf(
[2022-03-19 04:00:35,271] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 251, in read_single_udf
[2022-03-19 04:00:35,271] {spark_submit.py:488} INFO - f, return_type = read_command(pickleSer, infile)
[2022-03-19 04:00:35,272] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 71, in read_command
[2022-03-19 04:00:35,273] {spark_submit.py:488} INFO - command = serializer._read_with_length(file)
[2022-03-19 04:00:35,274] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 160, in _read_with_length
[2022-03-19 04:00:35,275] {spark_submit.py:488} INFO - return self.loads(obj)
[2022-03-19 04:00:35,276] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 430, in loads
[2022-03-19 04:00:35,277] {spark_submit.py:488} INFO - return pickle.loads(obj, encoding=encoding)
[2022-03-19 04:00:35,277] {spark_submit.py:488} INFO - ModuleNotFoundError: No module named 'keras'
[2022-03-19 04:00:35,279] {spark_submit.py:488} INFO - ) [duplicate 2]
[2022-03-19 04:00:35,280] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 7) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()
[2022-03-19 04:00:35,350] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO TaskSetManager: Lost task 0.3 in stage 2.0 (TID 7) on 172.18.0.4, executor 0: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
[2022-03-19 04:00:35,352] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 603, in main
[2022-03-19 04:00:35,353] {spark_submit.py:488} INFO - func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)
[2022-03-19 04:00:35,354] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 338, in read_udfs
[2022-03-19 04:00:35,355] {spark_submit.py:488} INFO - arg_offsets, udf = read_single_udf(
[2022-03-19 04:00:35,355] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 251, in read_single_udf
[2022-03-19 04:00:35,356] {spark_submit.py:488} INFO - f, return_type = read_command(pickleSer, infile)
[2022-03-19 04:00:35,357] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 71, in read_command
[2022-03-19 04:00:35,358] {spark_submit.py:488} INFO - command = serializer._read_with_length(file)
[2022-03-19 04:00:35,358] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 160, in _read_with_length
[2022-03-19 04:00:35,359] {spark_submit.py:488} INFO - return self.loads(obj)
[2022-03-19 04:00:35,360] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 430, in loads
[2022-03-19 04:00:35,361] {spark_submit.py:488} INFO - return pickle.loads(obj, encoding=encoding)
[2022-03-19 04:00:35,363] {spark_submit.py:488} INFO - ModuleNotFoundError: No module named 'keras'
[2022-03-19 04:00:35,365] {spark_submit.py:488} INFO - ) [duplicate 3]
[2022-03-19 04:00:35,365] {spark_submit.py:488} INFO - 22/03/19 04:00:35 ERROR TaskSetManager: Task 0 in stage 2.0 failed 4 times; aborting job
[2022-03-19 04:00:35,366] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2022-03-19 04:00:35,367] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO TaskSchedulerImpl: Cancelling stage 2
[2022-03-19 04:00:35,368] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
[2022-03-19 04:00:35,369] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) failed in 5.530 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 7) (172.18.0.4 executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
[2022-03-19 04:00:35,370] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 603, in main
[2022-03-19 04:00:35,370] {spark_submit.py:488} INFO - func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)
[2022-03-19 04:00:35,371] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 338, in read_udfs
[2022-03-19 04:00:35,372] {spark_submit.py:488} INFO - arg_offsets, udf = read_single_udf(
[2022-03-19 04:00:35,372] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 251, in read_single_udf
[2022-03-19 04:00:35,373] {spark_submit.py:488} INFO - f, return_type = read_command(pickleSer, infile)
[2022-03-19 04:00:35,374] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 71, in read_command
[2022-03-19 04:00:35,374] {spark_submit.py:488} INFO - command = serializer._read_with_length(file)
[2022-03-19 04:00:35,375] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 160, in _read_with_length
[2022-03-19 04:00:35,376] {spark_submit.py:488} INFO - return self.loads(obj)
[2022-03-19 04:00:35,377] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 430, in loads
[2022-03-19 04:00:35,377] {spark_submit.py:488} INFO - return pickle.loads(obj, encoding=encoding)
[2022-03-19 04:00:35,378] {spark_submit.py:488} INFO - ModuleNotFoundError: No module named 'keras'
[2022-03-19 04:00:35,379] {spark_submit.py:488} INFO - 
[2022-03-19 04:00:35,379] {spark_submit.py:488} INFO - at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)
[2022-03-19 04:00:35,380] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)
[2022-03-19 04:00:35,381] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)
[2022-03-19 04:00:35,382] {spark_submit.py:488} INFO - at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)
[2022-03-19 04:00:35,382] {spark_submit.py:488} INFO - at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
[2022-03-19 04:00:35,383] {spark_submit.py:488} INFO - at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2022-03-19 04:00:35,384] {spark_submit.py:488} INFO - at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2022-03-19 04:00:35,385] {spark_submit.py:488} INFO - at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
[2022-03-19 04:00:35,385] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
[2022-03-19 04:00:35,386] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)
[2022-03-19 04:00:35,387] {spark_submit.py:488} INFO - at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)
[2022-03-19 04:00:35,387] {spark_submit.py:488} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
[2022-03-19 04:00:35,388] {spark_submit.py:488} INFO - at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
[2022-03-19 04:00:35,388] {spark_submit.py:488} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2022-03-19 04:00:35,389] {spark_submit.py:488} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2022-03-19 04:00:35,390] {spark_submit.py:488} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2022-03-19 04:00:35,390] {spark_submit.py:488} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2022-03-19 04:00:35,391] {spark_submit.py:488} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2022-03-19 04:00:35,391] {spark_submit.py:488} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2022-03-19 04:00:35,392] {spark_submit.py:488} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
[2022-03-19 04:00:35,393] {spark_submit.py:488} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2022-03-19 04:00:35,393] {spark_submit.py:488} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2022-03-19 04:00:35,394] {spark_submit.py:488} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2022-03-19 04:00:35,395] {spark_submit.py:488} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2022-03-19 04:00:35,395] {spark_submit.py:488} INFO - 
[2022-03-19 04:00:35,396] {spark_submit.py:488} INFO - Driver stacktrace:
[2022-03-19 04:00:35,396] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO DAGScheduler: Job 2 failed: showString at NativeMethodAccessorImpl.java:0, took 5.568447 s
[2022-03-19 04:00:35,415] {spark_submit.py:488} INFO - Traceback (most recent call last):
[2022-03-19 04:00:35,416] {spark_submit.py:488} INFO - File "/usr/local/share_storages/spark_jobs/demo/job.py", line 78, in <module>
[2022-03-19 04:00:35,417] {spark_submit.py:488} INFO - print(predictions.show())
[2022-03-19 04:00:35,418] {spark_submit.py:488} INFO - File "/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 494, in show
[2022-03-19 04:00:35,419] {spark_submit.py:488} INFO - File "/usr/local/lib/python3.9/site-packages/pyspark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1321, in __call__
[2022-03-19 04:00:35,420] {spark_submit.py:488} INFO - File "/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
[2022-03-19 04:00:35,431] {spark_submit.py:488} INFO - pyspark.sql.utils.PythonException:
[2022-03-19 04:00:35,433] {spark_submit.py:488} INFO - An exception was thrown from the Python worker. Please see the stack trace below.
[2022-03-19 04:00:35,434] {spark_submit.py:488} INFO - Traceback (most recent call last):
[2022-03-19 04:00:35,435] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 603, in main
[2022-03-19 04:00:35,436] {spark_submit.py:488} INFO - func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)
[2022-03-19 04:00:35,437] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 338, in read_udfs
[2022-03-19 04:00:35,437] {spark_submit.py:488} INFO - arg_offsets, udf = read_single_udf(
[2022-03-19 04:00:35,438] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 251, in read_single_udf
[2022-03-19 04:00:35,439] {spark_submit.py:488} INFO - f, return_type = read_command(pickleSer, infile)
[2022-03-19 04:00:35,439] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 71, in read_command
[2022-03-19 04:00:35,440] {spark_submit.py:488} INFO - command = serializer._read_with_length(file)
[2022-03-19 04:00:35,441] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 160, in _read_with_length
[2022-03-19 04:00:35,442] {spark_submit.py:488} INFO - return self.loads(obj)
[2022-03-19 04:00:35,443] {spark_submit.py:488} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 430, in loads
[2022-03-19 04:00:35,443] {spark_submit.py:488} INFO - return pickle.loads(obj, encoding=encoding)
[2022-03-19 04:00:35,444] {spark_submit.py:488} INFO - ModuleNotFoundError: No module named 'keras'
[2022-03-19 04:00:35,445] {spark_submit.py:488} INFO - 
[2022-03-19 04:00:35,964] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO SparkContext: Invoking stop() from shutdown hook
[2022-03-19 04:00:35,978] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO SparkUI: Stopped Spark web UI at http://616fa5651a96:4040
[2022-03-19 04:00:35,984] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO StandaloneSchedulerBackend: Shutting down all executors
[2022-03-19 04:00:35,985] {spark_submit.py:488} INFO - 22/03/19 04:00:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2022-03-19 04:00:36,042] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2022-03-19 04:00:36,098] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO MemoryStore: MemoryStore cleared
[2022-03-19 04:00:36,105] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO BlockManager: BlockManager stopped
[2022-03-19 04:00:36,118] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO BlockManagerMaster: BlockManagerMaster stopped
[2022-03-19 04:00:36,127] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2022-03-19 04:00:36,143] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO SparkContext: Successfully stopped SparkContext
[2022-03-19 04:00:36,144] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO ShutdownHookManager: Shutdown hook called
[2022-03-19 04:00:36,145] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-fbd02288-746a-416f-ad6b-4ec5adddfcf6/pyspark-1d577348-e17b-407c-91de-fbe25d735ff0
[2022-03-19 04:00:36,189] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-13c55c74-02a7-4085-b498-5831213d0118
[2022-03-19 04:00:36,195] {spark_submit.py:488} INFO - 22/03/19 04:00:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-fbd02288-746a-416f-ad6b-4ec5adddfcf6
[2022-03-19 04:00:36,379] {taskinstance.py:1718} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1334, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1460, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1516, in _execute_task
    result = execute_callable(context=context)
  File "/usr/local/lib/python3.9/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/usr/local/lib/python3.9/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 419, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master spark://spark-master:7077 --name demo --queue root.default //usr/local/share_storages/spark_jobs/demo/job.py. Error code is: 1.
[2022-03-19 04:00:36,389] {taskinstance.py:1272} INFO - Marking task as FAILED. dag_id=demo_pipeline, task_id=document_etl, execution_date=20220317T193245, start_date=20220319T035946, end_date=20220319T040036
[2022-03-19 04:00:36,468] {standard_task_runner.py:89} ERROR - Failed to execute job 32 for task document_etl
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/usr/local/lib/python3.9/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1334, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1460, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1516, in _execute_task
    result = execute_callable(context=context)
  File "/usr/local/lib/python3.9/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/usr/local/lib/python3.9/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 419, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master spark://spark-master:7077 --name demo --queue root.default //usr/local/share_storages/spark_jobs/demo/job.py. Error code is: 1.
[2022-03-19 04:00:36,512] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-03-19 04:00:36,538] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
